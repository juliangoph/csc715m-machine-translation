# Cebuano â†’ Tagalog Machine Translation Project (NLLB Fine-Tuning + Pivot + Back-Translation)

This project implements a full MT workflow using the **facebook/nllb-200-distilled-600M** model, fine-tuned to translate **Cebuano â†’ Tagalog**.
 It includes:

- Data preparation
- Zero-shot baseline
- Fine-tuning
- Pivot translation
- Back-translation (BT)
- Evaluation
- Error analysis
- Human evaluation

All scripts were rewritten for clarity and compatibility across environments.

------

## **Project Structure**

```
project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original parallel text (source.txt, target.txt)
â”‚   â”œâ”€â”€ processed/              # Cleaned TSV splits (train/dev/test + BT augment)
â”‚   â””â”€â”€ mono/
â”‚       â””â”€â”€ target/             # Monolingual Tagalog mined for back-translation
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ baseline/               # Zero-shot results
â”‚   â”œâ”€â”€ finetune/               # Fine-tuned Cebuanoâ†’Tagalog model
â”‚   â”œâ”€â”€ finetune_bt/            # Fine-tuned + Back-Translation model
â”‚   â””â”€â”€ pivot/                  # Pivot translation results
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_overview.ipynb
â”‚   â”œâ”€â”€ 01_data_prep.ipynb
â”‚   â”œâ”€â”€ 02_baseline.ipynb
â”‚   â”œâ”€â”€ 03_finetune.ipynb
â”‚   â”œâ”€â”€ 04_pivot_bt_eval.ipynb
â”‚   â”œâ”€â”€ 05_error_analysis.ipynb
â”‚   â””â”€â”€ 06_report.ipynb         # Final PDF-ready report
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ prepare/
    â”‚   â”œâ”€â”€ convert_tmx.py
    â”‚   â”œâ”€â”€ make_splits.py
    â”‚   â””â”€â”€ mine_mono_tagalog.py
    â”‚
    â”œâ”€â”€ decode/
    â”‚   â””â”€â”€ translate_simple.py
    â”‚
    â”œâ”€â”€ train/
    â”‚   â””â”€â”€ finetune.py         # Main fine-tuning script
    â”‚
    â””â”€â”€ eval/
        â””â”€â”€ evaluate.py         # Unified evaluation script (BLEU, chrF, hypotheses)
```

------

## **Language Setup**

- **Source language â†’ Cebuano (`ceb_Latn`)**
- **Target language â†’ Tagalog (`tgl_Latn`)**

These codes are used consistently across training, decoding, and evaluation.

------

## **Notebooks Overview**

### **00_overview.ipynb**

Defines global project settings:

- Language direction (Cebuano â†’ Tagalog)
- Model
- Seed
- Experiment folders
- High-level workflow map

------

### **01_data_prep.ipynb**

Creates train/dev/test splits:

- Cleans raw source/target files
- Builds `train.tsv`, `dev.tsv`, `test.tsv`
- Shows random samples for sanity checking

Uses `make_splits.py`.

------

### **02_baseline.ipynb**

Runs **zero-shot** NLLB translation:

- Extracts test.src and test.ref
- Calls `translate_simple.py` for NLLB
- Computes baseline BLEU/chrF

Output: `experiments/baseline/metrics.json`

------

### **03_finetune.ipynb**

Fine-tunes NLLB for **Cebuano â†’ Tagalog**:

- Loads TSV datasets
- Applies language tags
- Calls the CLI script:

```
!python ../src/train/finetune.py \
  --train ../data/processed/train.tsv \
  --dev ../data/processed/dev.tsv \
  --out ../experiments/finetune
```

------

### **04_pivot_bt_eval.ipynb**

Two tasks:

#### **A) Pivot Translation**

- Cebuano â†’ Waray â†’ Tagalog
- Scored with BLEU/chrF

#### **B) Back-Translation (BT)**

1. Mined Cebuano monolingual text â†’ `mine_mono_tagalog.py`
2. Cebuano â†’ Tagalog synthetic back-translations
3. Create:

```
train_plus_bt.tsv = train.tsv + synthetic BT pairs
```

1. Re-train:

```
!python ../src/train/finetune.py \
  --train ../data/processed/train_plus_bt.tsv \
  --dev ../data/processed/dev.tsv \
  --out ../experiments/finetune_bt
```

------

### **05_error_analysis.ipynb**

Compares:

- baseline
- finetune
- pivot
- finetune_bt

Does:

- Sentence-level similarity (difflib)
- Top improvements vs regressions
- Negation checks
- Numerical handling
- Structure stability

------

### **06_report.ipynb**

A clean, PDF-ready compilation:

- Motivation
- Methodology
- Model setup
- Pivot & BT results
- Human evaluation (50-sentence set)
- Conclusions & future work

------

## **ðŸ“‚ Scripts Overview**

### **prepare/make_splits.py**

Creates train/dev/test TSV files with filtering:

- Removes duplicates
- Removes very short / very long lines
- Shuffles deterministically

------

### **prepare/mine_mono_tagalog.py**

Extracts monolingual Cebuano from existing target training data.
 Used for back-translation.

------

### **decode/translate_simple.py**

Lightweight translation script for:

- Baseline
- Pivot
- Back-translation synthetic generation

Automatically prepends the source language code.

------

### **train/finetune.py**

**Main training script**
 Features:

- Automatic language token resolution
- bf16/fp16 automatic mixed precision
- Fully compatible CLI
- Clean training pipeline

Example:

```
python src/train/finetune.py \
  --train data/processed/train.tsv \
  --dev data/processed/dev.tsv \
  --out experiments/finetune \
  --code_src ceb_Latn --code_tgt tgl_Latn
```

------

### **eval/evaluate.py**

Unified evaluator:

- Loads model directory
- Translates test set in batches
- Computes BLEU, chrF (SacreBLEU 2.x)
- Saves hypotheses
- Outputs metrics JSON

Example:

```
python src/eval/evaluate.py \
  --model_dir experiments/finetune_bt \
  --test_tsv data/processed/test.tsv \
  --out_json experiments/finetune_bt/metrics.json \
  --save_hyp experiments/finetune_bt/hyp.txt \
  --code_src ceb_Latn \
  --code_tgt tgl_Latn
```

