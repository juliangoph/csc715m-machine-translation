{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efc6c5f",
   "metadata": {},
   "source": [
    "# 02 — Zero-shot Baseline & Scoring\n",
    "\n",
    "**Purpose:**\n",
    " Run the unmodified NLLB model directly on your test data to create a **baseline** system for comparison.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Extract test sources (`test.src`) and references (`test.ref`) from `test.tsv`.\n",
    "2. Call your `translate_simple.py` script to generate predictions (`hyp.txt`).\n",
    "3. Score with `score.py` to compute BLEU and chrF2.\n",
    "4. Print metrics to verify baseline performance.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "- `experiments/baseline/test.src`\n",
    "- `experiments/baseline/test.ref`\n",
    "- `experiments/baseline/hyp.txt`\n",
    "- `experiments/baseline/metrics.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01d0941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared: ..\\experiments\\baseline\\test.src and ..\\experiments\\baseline\\test.ref lines: 2750\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path(\"..\")                 # project root (one level up from notebooks/)\n",
    "PP   = ROOT / \"data\" / \"processed\"\n",
    "EXP  = ROOT / \"experiments\" / \"baseline\"\n",
    "EXP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(PP / \"test.tsv\", sep=\"\\t\", header=None, names=[\"src\",\"tgt\"])\n",
    "(df[\"src\"]).to_csv(EXP / \"test.src\", index=False, header=False, encoding=\"utf-8\")\n",
    "(df[\"tgt\"]).to_csv(EXP / \"test.ref\", index=False, header=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Prepared:\", EXP / \"test.src\", \"and\", EXP / \"test.ref\", \"lines:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec76351d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,750 lines from ..\\experiments\\baseline\\test.src\n",
      "Loading model: facebook/nllb-200-distilled-600M\n",
      "Using source=tgl_Latn tag='tgl_Latn' → target=ceb_Latn (id=256035)\n",
      "Device: cuda | batch=12 | beams=2\n",
      "✅ Wrote 2750 translations → ..\\experiments\\baseline\\hyp.txt\n"
     ]
    }
   ],
   "source": [
    "!python ../src/decode/translate_simple.py \\\n",
    "  --model facebook/nllb-200-distilled-600M \\\n",
    "  --src ../experiments/baseline/test.src \\\n",
    "  --out ../experiments/baseline/hyp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173467f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Length mismatch: ref=3093 hyp=2750 — truncating to 2750\n",
      "{\n",
      "  \"BLEU\": 1.57,\n",
      "  \"chrF2\": 18.85,\n",
      "  \"ref_len\": 102401,\n",
      "  \"sys_len\": 88718,\n",
      "  \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.5.1\",\n",
      "  \"sacrebleu_version\": \"2.5.1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python ../src/eval/score.py \\\n",
    "  --ref ../experiments/baseline/test.ref \\\n",
    "  --hyp ../experiments/baseline/hyp.txt \\\n",
    "  --out ../experiments/baseline/metrics.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
